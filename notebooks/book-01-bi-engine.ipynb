{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Book 1: AI Builder's Launchpad - Business Intelligence Engine\n",
        "## One-Click CSV ‚Üí Insights Pipeline\n",
        "\n",
        "---\n",
        "\n",
        "**What this notebook does:**\n",
        "- Loads sample customer feedback CSV\n",
        "- Runs it through a 5-node AI pipeline\n",
        "- Generates an executive insights report\n",
        "\n",
        "**Time to complete:** ~3 minutes\n",
        "**Cost:** ~$0.02 (200 records)\n",
        "\n",
        "---\n",
        "\n",
        "### Quick Start\n",
        "1. **Get an API key:** Go to [console.anthropic.com](https://console.anthropic.com/) ‚Üí API Keys ‚Üí Create Key\n",
        "2. **Paste below:** Replace `YOUR_API_KEY_HERE`\n",
        "3. **Run all:** Runtime ‚Üí Run all cells (or press Shift+Enter on each)\n",
        "\n",
        "**Colab Pro Tip:** Use GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU) for faster processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 0: Setup & Configuration\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Install dependencies, configure API, run sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîë Paste Your Anthropic API Key\n",
        "import os\n",
        "\n",
        "# @markdown ### Enter your API key below (starts with `sk-ant-`)\n",
        "API_KEY = \"YOUR_API_KEY_HERE\"  # @param {type:\"string\"}\n",
        "\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = API_KEY\n",
        "\n",
        "print(\"‚úÖ API key configured!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚öôÔ∏è Model Configuration\n",
        "# @markdown Choose your model:\n",
        "# @markdown - **Haiku:** Fast, cheap (~$0.0001/record) - recommended for bulk\n",
        "# @markdown - **Sonnet:** Smarter, more expensive (~$0.003/record) - for complex tasks\n",
        "\n",
        "MODEL_CHOICE = \"haiku\"  # @param [\"haiku\", \"sonnet\"]\n",
        "\n",
        "if MODEL_CHOICE == \"haiku\":\n",
        "    TRIAGE_MODEL = \"claude-3-5-haiku-latest\"\n",
        "    SYNTHESIS_MODEL = \"claude-3-5-haiku-latest\"\n",
        "    COST_PER_1K = 0.00025  # Input + output estimate\n",
        "    print(\"üåÄ Using Claude 3.5 Haiku: Fast & Cheap\")\n",
        "else:\n",
"    TRIAGE_MODEL = \"claude-sonnet-4-6-latest\"\n",
"    SYNTHESIS_MODEL = \"claude-sonnet-4-6-latest\"\n",
        "    COST_PER_1K = 0.003\n",
        "    print(\"üß† Using Claude Sonnet 4.6: Smarter & Slower\")\n",
        "\n",
        "print(f\"Estimated cost per record: ${COST_PER_1K:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üì¶ Install Dependencies\n",
        "!pip install anthropic pandas pydantic -q\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚úÖ Sanity Check: Test API Connection\n",
        "import anthropic\n",
        "import time\n",
        "\n",
        "client = anthropic.Anthropic()\n",
        "\n",
        "start = time.time()\n",
        "response = client.messages.create(\n",
        "    model=TRIAGE_MODEL,\n",
        "    max_tokens=50,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Say 'Hello from Book 1!' and nothing else.\"}]\n",
        ")\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(f\"‚úÖ API Connection Successful!\")\n",
        "print(f\"üìù Response: {response.content[0].text}\")\n",
        "print(f\"‚è±Ô∏è Latency: {elapsed:.2f} seconds\")\n",
        "print(f\"üí∞ Tokens: {response.usage.input_tokens} in + {response.usage.output_tokens} out\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Data Ingestion (Chapter 7)\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Load and clean the CSV data.\n",
        "\n",
        "**What happens:**\n",
        "- Create sample data (or load your own)\n",
        "- Clean nulls and normalize types\n",
        "- Prepare for AI processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üì• Load Data (Sample or Upload)\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Create sample customer feedback data\n",
        "sample_csv = \"\"\"email_id,email\n",
        "1,My invoice shows the wrong amount this month. I was charged $250 but should be $200.\n",
        "2,The app crashes every time I try to upload a file. Very frustrating!\n",
        "3,Can you add a dark mode feature? The current white background hurts my eyes.\n",
        "4,I need a refund for my last order. The product arrived damaged.\n",
        "5,Thanks for the great service! Love using your platform.\n",
        "6,Our entire team cannot access the dashboard since this morning. We have a client presentation in 2 hours!\n",
        "7,The billing page shows my account as inactive but I just paid yesterday.\n",
        "8,How do I export my data to Excel? Cannot find the option anywhere.\n",
        "9,The API returns a 500 error when I try to create a new project.\n",
        "10,I have been waiting 3 days for a response to my support ticket. This is unacceptable!\n",
        "11,The mobile app sync is broken. My changes don't appear on other devices.\n",
        "12,Can you explain the new pricing structure? It seems more expensive.\n",
        "13,Found a bug: the date filter doesn't work on the reports page.\n",
        "14,I want to upgrade to the enterprise plan. Who do I contact?\n",
        "15,The email notifications are delayed by about 2 hours.\n",
        "\"\"\"\n",
        "\n",
        "# Option 1: Use sample data\n",
        "USE_SAMPLE = True  # @param {type:\"boolean\"}\n",
        "\n",
        "if USE_SAMPLE:\n",
        "    df = pd.read_csv(StringIO(sample_csv))\n",
        "    print(f\"üìä Loaded {len(df)} sample records\")\n",
        "else:\n",
        "    # Option 2: Upload your own CSV\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    df = pd.read_csv(filename)\n",
        "    print(f\"üìä Loaded {len(df)} records from {filename}\")\n",
        "\n",
        "# Display first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üßπ Data Cleaning (Chapter 7: Five Operations)\n",
        "\n",
        "# Operation 1: Null Normalization\n",
        "df[\"email\"] = df[\"email\"].fillna(\"\")\n",
        "\n",
        "# Filter empty rows\n",
        "df = df[df[\"email\"].str.strip() != \"\"]\n",
        "\n",
        "# Operation 2: String Normalization (trim whitespace)\n",
        "df[\"email\"] = df[\"email\"].str.strip()\n",
        "\n",
        "print(f\"‚úÖ Cleaned data: {len(df)} valid records\")\n",
        "print(\"\\nüìã Sample cleaned records:\")\n",
        "for i, row in df.head(3).iterrows():\n",
        "    print(f\"  {i+1}. {row['email'][:60]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Node 1 - Triage (Chapters 3-4)\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Classify each email by category and urgency.\n",
        "\n",
        "**System Prompt:**\n",
        "- Role: Customer feedback analyst\n",
        "- Task: Classify into Billing, Technical, Feature Request, Refund, General\n",
        "- Output: JSON with category, urgency, summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîç Node 1: Triage Classification (Haiku)\n",
        "import json\n",
        "\n",
        "TRIAGE_SYSTEM = \"\"\"You are a customer feedback analyst.\n",
        "Classify the email into ONE category: [Billing, Technical, Feature Request, Refund, General].\n",
        "Assign urgency: [High, Medium, Low].\n",
        "\n",
        "Rules:\n",
        "- HIGH urgency: customer mentions outage, data loss, legal threat, or time-critical issue\n",
        "- Respond ONLY in this JSON format. No other text.\n",
        "\n",
        "{\n",
        "  \"category\": \"<category>\",\n",
        "  \"urgency\": \"<High | Medium | Low>\",\n",
        "  \"one_line_summary\": \"<max 15 words>\"\n",
        "}\"\"\"\n",
        "\n",
        "def triage_email(email_text: str) -> dict:\n",
        "    \"\"\"Classify a single email.\"\"\"\n",
        "    try:\n",
        "        response = client.messages.create(\n",
        "            model=TRIAGE_MODEL,\n",
        "            max_tokens=128,\n",
        "            temperature=0,\n",
        "            system=TRIAGE_SYSTEM,\n",
        "            messages=[{\"role\": \"user\", \"content\": f\"Classify: {email_text}\"}]\n",
        "        )\n",
        "        return json.loads(response.content[0].text)\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e), \"category\": \"ERROR\", \"urgency\": \"ERROR\"}\n",
        "\n",
        "# Run on all records\n",
        "print(\"üîç Running triage on all records...\")\n",
        "\n",
        "triage_results = []\n",
        "for idx, row in df.iterrows():\n",
        "    result = triage_email(row[\"email\"])\n",
        "    result[\"email_id\"] = row[\"email_id\"]\n",
        "    result[\"email\"] = row[\"email\"]\n",
        "    triage_results.append(result)\n",
        "    \n",
        "    if (len(triage_results)) % 5 == 0:\n",
        "        print(f\"  Processed {len(triage_results)}/{len(df)}...\")\n",
        "\n",
        "print(f\"\\n‚úÖ Triage complete! {len(triage_results)} records processed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üìä View Triage Results\n",
        "triage_df = pd.DataFrame(triage_results)\n",
        "\n",
        "print(\"üìà Category Distribution:\")\n",
        "print(triage_df[\"category\"].value_counts())\n",
        "\n",
        "print(\"\\nüìà Urgency Distribution:\")\n",
        "print(triage_df[\"urgency\"].value_counts())\n",
        "\n",
        "print(\"\\nüìã Sample Results:\")\n",
        "triage_df[[\"email_id\", \"category\", \"urgency\", \"one_line_summary\"]].head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Node 2 - Extraction (Chapter 5)\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Extract failure signals from high-priority emails.\n",
        "\n",
        "**What happens:**\n",
        "- Identify high-urgency emails\n",
        "- Extract specific failure details\n",
        "- Build failure signal database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üéØ Node 2: Extract Failure Signals (High Priority Only)\n",
        "\n",
        "EXTRACT_SYSTEM = \"\"\"You are a root-cause analyst.\n",
        "Extract the specific product failure from this feedback.\n",
        "Respond ONLY in JSON.\n",
        "\n",
        "{\n",
        "  \"failure_type\": \"<specific system or feature that failed>\",\n",
        "  \"customer_impact\": \"<what the customer could not do>\",\n",
        "  \"frequency_signal\": \"<'first time' | 'recurring' | 'unspecified'>\",\n",
        "  \"emotional_tone\": \"<frustrated | angry | neutral | satisfied>\"\n",
        "}\"\"\"\n",
        "\n",
        "def extract_failure(email_text: str) -> dict:\n",
        "    \"\"\"Extract failure details.\"\"\"\n",
        "    try:\n",
        "        response = client.messages.create(\n",
        "            model=TRIAGE_MODEL,\n",
        "            max_tokens=128,\n",
        "            temperature=0,\n",
        "            system=EXTRACT_SYSTEM,\n",
        "            messages=[{\"role\": \"user\", \"content\": email_text}]\n",
        "        )\n",
        "        return json.loads(response.content[0].text)\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Get high-priority emails\n",
        "high_priority = triage_df[triage_df[\"urgency\"] == \"High\"]\n",
        "print(f\"üéØ Found {len(high_priority)} high-priority emails\")\n",
        "\n",
        "# Extract failure signals\n",
        "failure_signals = []\n",
        "for idx, row in high_priority.iterrows():\n",
        "    signal = extract_failure(row[\"email\"])\n",
        "    signal[\"email_id\"] = row[\"email_id\"]\n",
        "    failure_signals.append(signal)\n",
        "\n",
        "print(f\"‚úÖ Extracted failure signals from {len(failure_signals)} high-priority emails\")\n",
        "\n",
        "if failure_signals:\n",
        "    print(\"\\nüìã Sample Failure Signals:\")\n",
        "    for fs in failure_signals[:3]:\n",
        "        print(f\"  - {fs.get('failure_type', 'N/A')}: {fs.get('customer_impact', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Node 3 - Aggregation (Chapter 4: Tier 1)\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Use Python (not AI) to count and group.\n",
        "\n",
        "**Why:**\n",
        "- AI counting is ~85% accurate\n",
        "- Python counting is 100% accurate\n",
        "- Much faster and cheaper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚ûï Node 3: Python Aggregation (Tier 1 - Rule-Based)\n",
        "from collections import Counter\n",
        "\n",
        "# Aggregate by category\n",
        "valid_results = [r for r in triage_results if \"error\" not in r.get(\"category\", \"\")]\n",
        "category_counts = Counter(r.get(\"category\", \"Unknown\") for r in valid_results)\n",
        "urgency_counts = Counter(r.get(\"urgency\", \"Unknown\") for r in valid_results)\n",
        "\n",
        "aggregated = {\n",
        "    \"total_emails\": len(triage_results),\n",
        "    \"successful\": len(valid_results),\n",
        "    \"failed\": len(triage_results) - len(valid_results),\n",
        "    \"by_category\": dict(category_counts),\n",
        "    \"by_urgency\": dict(urgency_counts),\n",
        "}\n",
        "\n",
        "print(\"üìä AGGREGATION RESULTS (Python - 100% Accurate)\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total emails: {aggregated['total_emails']}\")\n",
        "print(f\"Successful: {aggregated['successful']}\")\n",
        "print(f\"Failed: {aggregated['failed']}\")\n",
        "\n",
        "print(\"\\nüìà By Category:\")\n",
        "for cat, count in aggregated[\"by_category\"].items():\n",
        "    pct = count / aggregated['successful'] * 100\n",
        "    print(f\"  {cat}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\nüìà By Urgency:\")\n",
        "for urg, count in aggregated[\"by_urgency\"].items():\n",
        "    print(f\"  {urg}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Node 4 - Synthesis (Chapter 4)\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Generate executive insights using Sonnet (Tier 1 reasoning).\n",
        "\n",
        "**What happens:**\n",
        "- Feed statistics to Claude Sonnet\n",
        "- Generate actionable insights\n",
        "- Create narrative summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚úçÔ∏è Node 4: Executive Synthesis (Sonnet)\n",
        "\n",
        "SYNTHESIS_SYSTEM = \"\"\"You are a COO preparing a weekly feedback briefing.\n",
        "Base ALL conclusions on the provided statistics.\n",
        "Do not invent trends.\n",
        "Use plain language.\n",
        "Highlight top 3 actionable insights.\n",
        "Keep the executive summary to 3 paragraphs max.\"\"\"\n",
        "\n",
        "stats_summary = f\"\"\"\n",
        "Total emails analyzed: {aggregated['total_emails']}\n",
        "Success rate: {aggregated['successful']/aggregated['total_emails']:.1%}\n",
        "\n",
        "Category breakdown:\n",
        f\"{json.dumps(aggregated['by_category'], indent=2)}\n",
        "\n",
        "Urgency breakdown:\n",
        f\"{json.dumps(aggregated['by_urgency'], indent=2)}\n",
        "\n",
        "Top failure signals from high-priority emails:\n",
        f\"{json.dumps(failure_signals[:5], indent=2)}\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úçÔ∏è Generating executive synthesis...\")\n",
        "\n",
        "response = client.messages.create(\n",
        "    model=SYNTHESIS_MODEL,\n",
        "    max_tokens=1024,\n",
        "    temperature=0,\n",
        "    system=SYNTHESIS_SYSTEM,\n",
        "    messages=[{\"role\": \"user\", \"content\": stats_summary}]\n",
        ")\n",
        "\n",
        "synthesis = response.content[0].text\n",
        "print(\"‚úÖ Synthesis complete!\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXECUTIVE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(synthesis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Node 5 - Report Output (Chapter 5)\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Format everything into a clean Markdown report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üìù Node 5: Generate Markdown Report\n",
        "from datetime import datetime\n",
        "\n",
        "report = f\"\"\"# Customer Feedback Intelligence Report\n",
        "\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
        "**Total Emails Processed:** {aggregated['total_emails']}\n",
        "**Success Rate:** {aggregated['successful']/aggregated['total_emails']:.1%}\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "{synthesis}\n",
        "\n",
        "---\n",
        "\n",
        "## Category Breakdown\n",
        "\n",
        "| Category | Count | Percentage |\n",
        "|----------|-------|------------|\n",
        "\"\"\"\n",
        "\n",
        "for cat, count in aggregated[\"by_category\"].items():\n",
        "    pct = count / aggregated['successful'] * 100\n",
        "    report += f\"| {cat} | {count} | {pct:.1f}% |\\n\"\n",
        "\n",
        "report += f\"\"\"\n",
        "---\n",
        "\n",
        "## Urgency Distribution\n",
        "\n",
        "| Urgency | Count |\n",
        "|---------|-------|\n",
        "\"\"\"\n",
        "\n",
        "for urg, count in aggregated[\"by_urgency\"].items():\n",
        "    report += f\"| {urg} | {count} |\\n\"\n",
        "\n",
        "report += f\"\"\"\n",
        "---\n",
        "\n",
        "## High-Priority Failure Signals\n",
        "\n",
        "| Failure Type | Customer Impact | Frequency |\n",
        "|--------------|-----------------|-----------|\\n",
        "\"\"\"\n",
        "\n",
        "for fs in failure_signals:\n",
        "    ft = fs.get('failure_type', 'N/A')\n",
        "    ci = fs.get('customer_impact', 'N/A')\n",
        "    fr = fs.get('frequency_signal', 'N/A')\n",
        "    report += f\"| {ft} | {ci} | {fr} |\\n\"\n",
        "\n",
        "report += f\"\"\"\n",
        "---\n",
        "\n",
        "## Pipeline Metadata\n",
        "\n",
        "- **Triage Model:** {TRIAGE_MODEL}\n",
        "- **Synthesis Model:** {SYNTHESIS_MODEL}\n",
        "- **Estimated Cost:** ${len(df) * COST_PER_1K:.4f}\n",
        "\n",
        "---\n",
        "\n",
        "*Generated by Book 1: AI Builder's Launchpad - BI Engine*\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úÖ Report generated!\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üíæ Download Report\n",
        "from google.colab import files\n",
        "\n",
        "report_filename = \"feedback_intelligence_report.md\"\n",
        "with open(report_filename, \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "files.download(report_filename)\n",
        "print(f\"‚úÖ Report saved to {report_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Inline Failure Museum\n",
        "\n",
        "---\n",
        "\n",
        "**Purpose:** Deliberately trigger common errors and show how to fix them.\n",
        "\n",
        "**Instructions:** Run each cell to see the error, then uncomment the fix to see the solution.\n",
        "\n",
        "---\n",
        "\n",
        "### Error 1: JSON Parse Failure\n",
        "\n",
        "The model sometimes returns invalid JSON. Here's how to handle it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚ö†Ô∏è Error Demo: Invalid JSON Output\n",
        "\"\"\"\n",
        "PROBLEM: Sometimes the model returns text before/after JSON, causing parse failure.\n",
        "\"\"\"\n",
        "\n",
        "bad_response = \"\"\"\n",
        "Here's the classification:\n",
        "{\"category\": \"Billing\", \"urgency\": \"High\"}\n",
        "Let me know if you need anything else!\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    result = json.loads(bad_response)\n",
        "    print(\"‚úÖ Parsed successfully!\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"‚ùå JSON Parse Error: {e}\")\n",
        "    print(\"\\nüîß THE FIX:\")\n",
        "    print(\"\"\"\n",
        "# Extract JSON from response using regex\n",
        "import re\n",
        "json_match = re.search(r'\\{.*\\}', bad_response, re.DOTALL)\n",
        "if json_match:\n",
        "    result = json.loads(json_match.group())\n",
        "    print(f\"‚úÖ Fixed! Result: {result}\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚ö†Ô∏è Error Demo: Type Mismatch\n",
        "\"\"\"\n",
        "PROBLEM: Model returns string where we expect number.\n",
        "\"\"\"\n",
        "\n",
        "model_output = {\n",
        "    \"invoice_total\": \"150.00\",  # String, not float!\n",
        "    \"is_paid\": \"yes\"          # String, not bool!\n",
        "}\n",
        "\n",
        "try:\n",
        "    # This will fail in database!\n",
        "    print(f\"Type: {type(model_output['invoice_total'])}\")\n",
        "    # db.insert(amount=model_output['invoice_total'])  # FAILS!\n",
        "    print(\"‚ùå Type mismatch - would fail in database!\")\n",
        "    \n",
        "    print(\"\\nüîß THE FIX: Use Pydantic for validation\")\n",
        "    print(\"\"\"\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Invoice(BaseModel):\n",
        "    invoice_total: float  # Will auto-convert \"150.00\" ‚Üí 150.0\n",
        "    is_paid: bool        # Will auto-convert \"yes\" ‚Üí True\n",
        "\n",
        "validated = Invoice(**model_output)\n",
        "print(f\"‚úÖ Fixed! invoice_total={validated.invoice_total}, is_paid={validated.is_paid}\")\n",
        "\"\"\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚ö†Ô∏è Error Demo: Rate Limit\n",
        "\"\"\"\n",
        "PROBLEM: Too many API calls trigger rate limits.\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚ö†Ô∏è Rate Limit Demo\")\n",
        "print(\"=\"*40)\n",
        "print(\"\"\"\n",
        "ERROR MESSAGE:\n",
        "anthropic.RateLimitError: \n",
        "You exceeded your API rate limit. \n",
        "Please wait before making more requests.\n",
        "\n",
        "COMMON CAUSES:\n",
        "- Too many concurrent requests\n",
        "- Burst of calls exceeding quota\n",
        "- No backoff/retry logic\n",
        "\n",
        "üîß THE FIX:\n",
        "1. Add retry with exponential backoff\n",
        "2. Add rate limiting between calls\n",
        "```python\n",
        "import time\n",
        "\n",
        "def call_with_retry(prompt, max_retries=3):\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            return client.messages.create(...)\n",
        "        except RateLimitError:\n",
        "            wait_time = 2 ** attempt  # 1s, 2s, 4s\n",
        "            print(f\"Rate limited. Waiting {wait_time}s...\")\n",
        "            time.sleep(wait_time)\n",
        "    raise Exception(\"Max retries exceeded\")\n",
        "```\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Final Summary\n",
        "\n",
        "---\n",
        "\n",
        "### What You Just Built\n",
        "\n",
        "| Component | What It Does |\n",
        "|-----------|---------------|\n",
        "| **Node 1: Triage** | Classifies emails into categories (Billing, Technical, etc.) |\n",
        "| **Node 2: Extract** | Pulls failure signals from high-priority items |\n",
        "| **Node 3: Aggregate** | Counts using Python (100% accurate) |\n",
        "| **Node 4: Synthesis** | Generates executive insights with Sonnet |\n",
        "| **Node 5: Report** | Formats everything into Markdown |\n",
        "\n",
        "---\n",
        "\n",
        "### Cost Summary\n",
        "\n",
        f"- Records processed: **{len(df)}**\n",
        f"- API model: **{MODEL_CHOICE.upper()}**\n",
        f"- Estimated cost: **${len(df) * COST_PER_1K:.4f}**\n",
        f"- Human equivalent: **~1 hour of manual analysis**\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Run on your own data:** Upload a CSV with an `email` column\n",
        "2. **Expand the pipeline:** Add Node 2 extraction for all categories\n",
        "3. **Deploy:** Turn this into an API (Book 2)\n",
        "4. **Add RAG:** Connect to a knowledge base (Book 3)\n",
        "\n",
        "---\n",
        "\n",
        "**Reference:** This notebook mirrors Chapter 9: Shipping Day from *Book 1: The AI Builder's Launchpad*\n",
        "\n",
        "**Portfolio Proof:** Link this Colab in your resume/Upwork as \"Reference implementation: AI Business Intelligence Pipeline\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "name": "Book1_BI_Engine.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
